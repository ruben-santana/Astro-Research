{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"bf9f5869-1c19-4fc6-8c70-def2ea7cc8aa\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      var el = document.getElementById(\"bf9f5869-1c19-4fc6-8c70-def2ea7cc8aa\");\n",
       "      el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete window._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"bf9f5869-1c19-4fc6-8c70-def2ea7cc8aa\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'bf9f5869-1c19-4fc6-8c70-def2ea7cc8aa' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.6.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.6.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"bf9f5869-1c19-4fc6-8c70-def2ea7cc8aa\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.6.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.6.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.6.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.6.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"bf9f5869-1c19-4fc6-8c70-def2ea7cc8aa\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#kplr used to import koi data easier\n",
    "import kplr\n",
    "client = kplr.API()\n",
    "\n",
    "#used to open .fits files\n",
    "import pyfits\n",
    "# import astropy\n",
    "\n",
    "#Used for Plotting\n",
    "#Experimenting with this instead of using matplot.lib\n",
    "from bokeh.plotting import figure, show, output_file,output_notebook\n",
    "#Allows for viewing of plots on jupyter notebooks\n",
    "output_notebook()\n",
    "\n",
    "#For Maximum Likelihood\n",
    "from scipy import optimize\n",
    "\n",
    "#Used for scientific computing\n",
    "import numpy as np\n",
    "\n",
    "#For making copies of data\n",
    "import copy\n",
    "\n",
    "#Needed to correct median with 'nan' data points\n",
    "import math\n",
    "\n",
    "#For Periodogram\n",
    "from gatspy.periodic import LombScargleFast\n",
    "\n",
    "#Importing and notebook setup\n",
    "%matplotlib inline\n",
    "\n",
    "#For Plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#adjusting light curve data to be a horizontal line\n",
    "# keeps the first point of the data and makes rest of data horizontal with respect to that point\n",
    "\n",
    "def h_data (x, y):\n",
    "    #Using point-slope to make a model linear fit of data\n",
    "    slope_g = (f[-1]-f[0])/(t[-1]-t[0])\n",
    "    pt_x = x[20]\n",
    "    pt_y = y[20]\n",
    "    print 'slope: ',slope_g\n",
    "    x = np.linspace(min(t),max(t),len(f))\n",
    "\n",
    "    #Rough linear fit of data\n",
    "    new_y = slope_g*(x-pt_x)+pt_y\n",
    "    \n",
    "    #Making correction to original data to make horizontal\n",
    "    first_pt = new_y[0]\n",
    "    correction = new_y-first_pt\n",
    "    new_data = y - correction\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def periodogram(datax, datay, min_, max_, nyquist):\n",
    "    #finding periodogram\n",
    "    model = LombScargleFast().fit(datax, datay)\n",
    "    period, power = model.periodogram_auto(nyquist_factor=nyquist) # Default 50\n",
    "\n",
    "    #Plotting\n",
    "    plt.figure\n",
    "    plt.plot(period,power)\n",
    "    plt.ylabel('Power')\n",
    "    plt.xlabel('Period')# days\n",
    "    plt.xscale('log')\n",
    "    #used bottom line to zoom in periodogram\n",
    "#     plt.xlim(min_-1,max_+10)\n",
    "\n",
    "    # set range and find period\n",
    "    model.optimizer.period_range=(min_, max_)\n",
    "    period = model.best_period\n",
    "    print(\"period = {0}\".format(period))\n",
    "    return period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Making loop to get Median Smooth\n",
    " \n",
    "#jump - The number of pixels you are taking the median\n",
    "### ex. jump = 7, median over 7 points, replaces values inbetween with median\n",
    "### Before: [1,2,3,4,5,6,7]\n",
    "### After:  [1,4,4,4,4,4,7]\n",
    "\n",
    "\n",
    "def median_smooth(datay,jump,peak_min):\n",
    "    #n - determines section of data we are looking at\n",
    "    n = 1\n",
    "    \n",
    "    #Data that is being changed and smoothed\n",
    "    smooth_flux = copy.copy(datay)\n",
    "\n",
    "    #median smoothing loop\n",
    "    while n <= len(smooth_flux)-jump-1:    \n",
    "        #delta of data from one point to another\n",
    "        #used in for loop to leave troughs unchanged\n",
    "        max_change = 0\n",
    "        #Checks the max delta of data points for each jump\n",
    "        for i in range (n-1,n+jump-1):\n",
    "            delta = abs( h_flux[i]-h_flux[i+1])\n",
    "            if delta > max_change:\n",
    "                max_change = delta\n",
    "\n",
    "        #Makes range of points equal to median\n",
    "        if max_change < peak_min:\n",
    "            median = np.median(h_flux[n-1:n+jump])\n",
    "            \n",
    "            #This line corrects errors with data labeled at 'nan'\n",
    "            if math.isnan(median)==False:\n",
    "                smooth_flux[n:n+jump-2] = median\n",
    "\n",
    "#             #Leaves points unchaged when median is 'nan'\n",
    "#             else:\n",
    "#                 print 'Median: ', median\n",
    "#                 print 'Data Numbers Reserved: ', n-1, ' to ', n+jump-1\n",
    "#                 print 'Original Data: ', h_flux[n-1:n+jump]\n",
    "#                 print 'Smooth Data: ', smooth_flux[n-1:n+jump]\n",
    "#                 print 'Max Change: ', max_change\n",
    "#                 print ''\n",
    "#                 print ''\n",
    "# \n",
    "#         #Leaves troughs unchaged\n",
    "#         else:\n",
    "#             print 'Data Numbers Reserved: ', n-1, ' to ', n+jump-1\n",
    "#             print 'Original Data: ', datay[n-1:n+jump]\n",
    "#             print 'Smooth Data: ', smooth_flux[n-1:n+jump]\n",
    "#             print 'Max Change: ', max_change\n",
    "#             print ''\n",
    "#             print ''\n",
    "        n=n+jump\n",
    "    print 'First 100 Points'\n",
    "    print 'Before: '\n",
    "    print ''\n",
    "    print h_flux[0:99]\n",
    "    print ''\n",
    "    print 'After: '\n",
    "    print ''\n",
    "    print smooth_flux[0:99]\n",
    "    return smooth_flux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find a KOI.\n",
    "koi = client.koi(17.01)\n",
    "\n",
    "#period, period error (postive & negative)\n",
    "print 'Period w/ errors: ',(koi.koi_period, koi.koi_period_err1, koi.koi_period_err2)\n",
    "\n",
    "# This KOI has an associated star.\n",
    "star = koi.star\n",
    "print \"Associated Star Temperature: \",(star.kic_teff)\n",
    "\n",
    "#Download the lightcurves for this KOI.\n",
    "lightcurves = koi.get_light_curves()\n",
    "# for lc in lightcurves:\n",
    "#     print (lc.filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Like Curve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop over the datasets and read in the data.\n",
    "time, flux, ferr, quality = [], [], [], []\n",
    "for lc in lightcurves:\n",
    "    with lc.open() as f:\n",
    "        # The lightcurve data are in the first FITS HDU.\n",
    "        hdu_data = f[1].data\n",
    "        time.append(hdu_data[\"time\"])\n",
    "        flux.append(hdu_data[\"sap_flux\"])\n",
    "        ferr.append(hdu_data[\"sap_flux_err\"])\n",
    "        quality.append(hdu_data[\"sap_quality\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Time (BJD - 2454833)\n",
    "#Flux (e-/sec) + ____e+4\n",
    "#Which quarter do you want to look at?\n",
    "quarter =1\n",
    "t = time[quarter]\n",
    "f = flux[quarter]\n",
    "#Creating new plot with title and axis labels\n",
    "#Plot is an object\n",
    "lc_plot_17 = figure(\n",
    "    title='KOI-17: Quarter %d '% quarter, \n",
    "    x_axis_label='Time (BJD - 2454833)',\n",
    "    y_axis_label='Flux (e-/sec) e+4',\n",
    "    tools = 'hover,crosshair,pan,wheel_zoom,box_zoom,reset,tap,save,box_select')\n",
    "\n",
    "#adding x and y data for plot\n",
    "legend = 'KOI: Quarter %d' % quarter\n",
    "lc_plot_17.line(t, f,legend=legend)\n",
    "\n",
    "#showing results\n",
    "show(lc_plot_17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Fixing Data to Make it Horizontal (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Horizontalizing Data\n",
    "h_flux = h_data(t,f)\n",
    "\n",
    "#Plot is an object\n",
    "lc_h_17 = figure(\n",
    "    title='KOI-17: Horizontal, Quarter %d '% quarter, \n",
    "    x_axis_label='Time (BJD - 2454833)',\n",
    "    y_axis_label='Flux (e-/sec) e+4',\n",
    "    tools = 'hover,crosshair,pan,wheel_zoom,box_zoom,reset,tap,save,box_select')\n",
    "\n",
    "#adding x and y data for plot\n",
    "lc_h_17.line(t, h_flux,line_width=1,legend='Horizontal KOI-17',color='green')\n",
    "\n",
    "\n",
    "#showing results\n",
    "show(lc_h_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smooth_flux = median_smooth(h_flux,7,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median Smoothing of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot is an object\n",
    "lc_smooth_17 = figure(\n",
    "    title='KOI-17', \n",
    "    x_axis_label='Time (BJD - 2454833)',\n",
    "    y_axis_label='Flux (e-/sec) e+4',\n",
    "    tools = 'hover,crosshair,pan,wheel_zoom,box_zoom,reset,tap,save,box_select')\n",
    "\n",
    "#adding x and y data for plot\n",
    "lc_smooth_17.line(t, smooth_flux,legend='Median Smooth Data',color='orange')\n",
    "# lc_smooth_17.line(t, h_flux,legend='H Data',color='red')\n",
    "\n",
    "print smooth_flux[180:200]\n",
    "show(lc_smooth_17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "Finding Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Still need to work on Periodogram\n",
    "period = periodogram(t, f, 1,30,.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Step 1: Make a cut_off and only look at that data\n",
    "### Step 2: Find min flux of each trough\n",
    "### Step 3: Find the avg. time diff between each local min\n",
    "###Still need to makes this plot into a function and then will place it up above\n",
    "\n",
    "# cut_off is the max the point can be to pass the filter\n",
    "# f_change - change in flux from cutoff\n",
    "cut_off = 69200\n",
    "min_f = np.array([])\n",
    "min_t = np.array([])\n",
    "\n",
    "#Step 1: filters data to just the points below the cut_off\n",
    "for i in range(0,len(smooth_flux)):\n",
    "    f_change = smooth_flux[i] - cut_off\n",
    "    \n",
    "    #checks if it's lower than cut off\n",
    "    if f_change < 0:\n",
    "        min_f = np.append(min_f,[smooth_flux[i]])\n",
    "        min_t = np.append(min_t,[t[i]])\n",
    "\n",
    "# print min_f\n",
    "# print min_t\n",
    "\n",
    "#local_min - lowest point of troughs place holder\n",
    "#check - checks to see if new point is lower than previous local_min\n",
    "local_min = min_f[0]\n",
    "troughs_f = np.array([])\n",
    "troughs_t = np.array([])\n",
    "\n",
    "#Step 2: filters to just show only the lowest point of each trough\n",
    "for i in range(0,len(min_f)-1):\n",
    "    t_change = min_t[i+1] - min_t[i]\n",
    "    check = min_f[i]\n",
    "    # checks if it's lower than previous local_min\n",
    "    if check < local_min:\n",
    "        local_min = check\n",
    "        ndata = i\n",
    "    \n",
    "    #documents lowest point and resets check for next trough\n",
    "    if t_change > 1 or i > len(min_f)-3:\n",
    "        troughs_f = np.append(troughs_f, [local_min])\n",
    "        troughs_t = np.append(troughs_t, [min_t[ndata]])\n",
    "        local_min = cut_off\n",
    "        \n",
    "# print 'The min of each flux trough: ', troughs_f\n",
    "# print 'The corresponding time for each trough: ' ,troughs_t\n",
    "            \n",
    "all_periods = np.array([])\n",
    "\n",
    "#Step 3: finding average change in time from each trough\n",
    "for i in range(0,len(troughs_t)-1):\n",
    "    period = troughs_t[i+1]-troughs_t[i]\n",
    "    all_periods = np.append(all_periods,period)\n",
    "\n",
    "avg_period = np.mean(all_periods)\n",
    "# print 'All periods: ', all_periods\n",
    "print 'Avg. period: ', avg_period, ' days.'\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore Everything Below Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #using pyfits to open a quarter of data as .fits file\n",
    "# pyfits.open('c:/Users/rscsa/.kplr/data/lightcurves/010874614/kplr010874614-2009131105131_llc.fits')\n",
    "# print pyfits.hdu.image.PrimaryHDU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
